{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "\n",
    "# 获取alexNet预训练参数\n",
    "# alexNet = models.alexnet(pretrained=True)\n",
    "# torch.save(alexNet.state_dict(),'alexNet_weights.pth')\n",
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from collections import abc\n",
    "\"\"\"修改 alexnet 使其 iterable\"\"\"\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self,input_layer = 3,num_classes: int = 1000) -> None:\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(input_layer, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def __iter__(self,):\n",
    "        return SentenceIterator(self.features,self.avgpool,self.classifier)\n",
    "\n",
    "class SentenceIterator(abc.Iterator):\n",
    "    def __init__(self,features,avgpool,classifier):\n",
    "        self.features = features\n",
    "        self.avg_pool = avgpool\n",
    "        self.classifier = classifier\n",
    "        self._index = 0\n",
    "        self.len1 = len(features)\n",
    "        self.len2 = 1\n",
    "        self.len3 = len(classifier)\n",
    "\n",
    "\n",
    "    def __next__(self):\n",
    "        try:\n",
    "            if self._index < self.len1:\n",
    "                layer = self.features[self._index]\n",
    "            elif self._index < (self.len1 + self.len2):\n",
    "                layer = self.avg_pool\n",
    "            else:\n",
    "                layer = self.classifier[self._index - self.len1 - self.len2]\n",
    "        except IndexError:\n",
    "            raise StopIteration()\n",
    "        else:\n",
    "            self._index += 1\n",
    "\n",
    "        return layer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def alexnet(pretrained: bool = False, **kwargs) -> AlexNet:\n",
    "    model = AlexNet(**kwargs).to(device)\n",
    "    if pretrained:\n",
    "        state_dict = torch.load('./00_model_parameters/alexNet_weights.pth')\n",
    "        model.load_state_dict(state_dict)\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    使用与训练好的参数先预测一波fashionmnis图像分类的准确率\n",
    "\"\"\"\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "resize = 224\n",
    "trans = transforms.Compose([\n",
    "    transforms.Resize(resize),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "training_data = datasets.FashionMNIST(root = \"../data\",train=True,download=False,transform=trans)\n",
    "test_data = datasets.FashionMNIST(root = \"../data\",train=False,download=True,transform=trans)\n",
    "\n",
    "mytest_data = []\n",
    "for idx,(x,y) in enumerate(test_data):\n",
    "    mytest_data.append((torch.cat((x,x,x),dim=0),y))\n",
    "\n",
    "train_dataloader = DataLoader(training_data,batch_size=64,shuffle=True)\n",
    "test_dataloader = DataLoader(mytest_data,batch_size=64,shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all number: 640   correct number: 69.0\n",
      "Accuracy:  10.8% , avg loss :2.302552\n",
      "--------------------------------------------------\n",
      "all number: 1280   correct number: 132.0\n",
      "Accuracy:  10.3% , avg loss :2.302895\n",
      "--------------------------------------------------\n",
      "all number: 1920   correct number: 198.0\n",
      "Accuracy:  10.3% , avg loss :2.302572\n",
      "--------------------------------------------------\n",
      "all number: 2560   correct number: 259.0\n",
      "Accuracy:  10.1% , avg loss :2.302608\n",
      "--------------------------------------------------\n",
      "all number: 3200   correct number: 316.0\n",
      "Accuracy:  9.9% , avg loss :2.302572\n",
      "--------------------------------------------------\n",
      "all number: 3840   correct number: 385.0\n",
      "Accuracy:  10.0% , avg loss :2.302678\n",
      "--------------------------------------------------\n",
      "all number: 4480   correct number: 447.0\n",
      "Accuracy:  10.0% , avg loss :2.302655\n",
      "--------------------------------------------------\n",
      "all number: 5120   correct number: 507.0\n",
      "Accuracy:  9.9% , avg loss :2.302620\n",
      "--------------------------------------------------\n",
      "all number: 5760   correct number: 585.0\n",
      "Accuracy:  10.2% , avg loss :2.302610\n",
      "--------------------------------------------------\n",
      "all number: 6400   correct number: 662.0\n",
      "Accuracy:  10.3% , avg loss :2.302611\n",
      "--------------------------------------------------\n",
      "all number: 7040   correct number: 732.0\n",
      "Accuracy:  10.4% , avg loss :2.302694\n",
      "--------------------------------------------------\n",
      "all number: 7680   correct number: 773.0\n",
      "Accuracy:  10.1% , avg loss :2.302687\n",
      "--------------------------------------------------\n",
      "all number: 8320   correct number: 837.0\n",
      "Accuracy:  10.1% , avg loss :2.302694\n",
      "--------------------------------------------------\n",
      "all number: 8960   correct number: 893.0\n",
      "Accuracy:  10.0% , avg loss :2.302692\n",
      "--------------------------------------------------\n",
      "all number: 9600   correct number: 959.0\n",
      "Accuracy:  10.0% , avg loss :2.302667\n",
      "--------------------------------------------------\n",
      "test error :\n",
      " Accuracy:  10.0 , avg loss :2.302670\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    测定test数据集准确率\n",
    "    batch input [64,1,224,224]\n",
    "    batch label [64]\n",
    "\n",
    "    batch output [64,10]\n",
    "\"\"\"\n",
    "def test(dataloader,model,loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss,correct,all = 0,0,0\n",
    "    with torch.no_grad():\n",
    "        for idx,(X,y) in enumerate(dataloader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            all += 64\n",
    "            # X,y = X.to(device),y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred,y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "            if(all % 640 == 0):\n",
    "                print(f\"all number: {all}   correct number: {correct}\")\n",
    "                print(f\"Accuracy: {(100*(correct/all)) :> 0.1f}% , avg loss :{test_loss/(idx+1):>8f}\")\n",
    "                print(f\"--------------------------------------------------\")\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"test error :\\n Accuracy: {(100*correct) :> 0.1f} , avg loss :{test_loss:>8f}\")\n",
    "\n",
    "# 预训练最后输出维度1000 所以目前fashion数据集只能多加个 linear 1000->10\n",
    "# 后续换成cifar-10 数据集可以正常运行\n",
    "alexNet = nn.Sequential(\n",
    "    alexnet(pretrained=False,num_classes=1000),\n",
    "    nn.Linear(1000,10),\n",
    ").to(device)\n",
    "test(test_dataloader,alexNet,nn.CrossEntropyLoss())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Conv2d output shape:\t torch.Size([10000, 64, 55, 55]) \t computation time: 31.926000 s\n",
      "ReLU output shape:\t torch.Size([10000, 64, 55, 55]) \t computation time: 2.232000 s\n",
      "MaxPool2d output shape:\t torch.Size([10000, 64, 27, 27]) \t computation time: 3.585000 s\n",
      "Conv2d output shape:\t torch.Size([10000, 192, 27, 27]) \t computation time: 32.452000 s\n",
      "ReLU output shape:\t torch.Size([10000, 192, 27, 27]) \t computation time: 0.204000 s\n",
      "MaxPool2d output shape:\t torch.Size([10000, 192, 13, 13]) \t computation time: 2.837000 s\n",
      "Conv2d output shape:\t torch.Size([10000, 384, 13, 13]) \t computation time: 6.940000 s\n",
      "ReLU output shape:\t torch.Size([10000, 384, 13, 13]) \t computation time: 0.405000 s\n",
      "Conv2d output shape:\t torch.Size([10000, 256, 13, 13]) \t computation time: 7.328000 s\n",
      "ReLU output shape:\t torch.Size([10000, 256, 13, 13]) \t computation time: 0.230000 s\n",
      "Conv2d output shape:\t torch.Size([10000, 256, 13, 13]) \t computation time: 13.279000 s\n",
      "ReLU output shape:\t torch.Size([10000, 256, 13, 13]) \t computation time: 0.155000 s\n",
      "MaxPool2d output shape:\t torch.Size([10000, 256, 6, 6]) \t computation time: 0.700000 s\n",
      "AdaptiveAvgPool2d output shape:\t torch.Size([10000, 256, 6, 6]) \t computation time: 0.168000 s\n",
      "Flatten output shape:\t torch.Size([10000, 9216]) \t computation time: 0.007000 s\n",
      "Dropout output shape:\t torch.Size([10000, 9216]) \t computation time: 0.702000 s\n",
      "Linear output shape:\t torch.Size([10000, 4096]) \t computation time: 2.506000 s\n",
      "ReLU output shape:\t torch.Size([10000, 4096]) \t computation time: 0.009000 s\n",
      "Dropout output shape:\t torch.Size([10000, 4096]) \t computation time: 0.250000 s\n",
      "Linear output shape:\t torch.Size([10000, 4096]) \t computation time: 1.139000 s\n",
      "ReLU output shape:\t torch.Size([10000, 4096]) \t computation time: 0.008000 s\n",
      "Linear output shape:\t torch.Size([10000, 1000]) \t computation time: 0.339000 s\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    尝试分解每层的计算\n",
    "\"\"\"\n",
    "import time\n",
    "x = torch.rand(size=(10000,3,224,224))\n",
    "x = x.to(device)\n",
    "alexNet2 = alexnet(input_layer = 3,num_classes = 1000)\n",
    "print(next(alexNet2.parameters()).device)\n",
    "\n",
    "for layer in alexNet2:\n",
    "    start_time = int(round(time.time() * 1000))\n",
    "    x = layer(x)\n",
    "    end_time = int(round(time.time() * 1000))\n",
    "    # print(x.device)\n",
    "    print(layer.__class__.__name__,'output shape:\\t',x.shape,\n",
    "          f'\\t computation time: {(end_time - start_time)/1000 :>3f} s')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    ")\n",
    "\n",
    "print(len(model))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "------------------------------------------------------------------\n",
      "1-Conv2d computation time: 0.345000 s\n",
      "output shape: torch.Size([100, 64, 55, 55]) \t transport_num:19360000 \t transport_size:619.52M\n",
      "weight  :  parameters size torch.Size([64, 3, 11, 11]) \t parameters number 23232\n",
      "bias  :  parameters size torch.Size([64]) \t parameters number 64\n",
      "------------------------------------------------------------------\n",
      "2-ReLU computation time: 0.003000 s\n",
      "output shape: torch.Size([100, 64, 55, 55]) \t transport_num:19360000 \t transport_size:619.52M\n",
      "------------------------------------------------------------------\n",
      "3-MaxPool2d computation time: 0.020000 s\n",
      "output shape: torch.Size([100, 64, 27, 27]) \t transport_num:4665600 \t transport_size:149.2992M\n",
      "------------------------------------------------------------------\n",
      "4-Conv2d computation time: 0.092000 s\n",
      "output shape: torch.Size([100, 192, 27, 27]) \t transport_num:13996800 \t transport_size:447.89759999999995M\n",
      "weight  :  parameters size torch.Size([192, 64, 5, 5]) \t parameters number 307200\n",
      "bias  :  parameters size torch.Size([192]) \t parameters number 192\n",
      "------------------------------------------------------------------\n",
      "5-ReLU computation time: 0.002000 s\n",
      "output shape: torch.Size([100, 192, 27, 27]) \t transport_num:13996800 \t transport_size:447.89759999999995M\n",
      "------------------------------------------------------------------\n",
      "6-MaxPool2d computation time: 0.020000 s\n",
      "output shape: torch.Size([100, 192, 13, 13]) \t transport_num:3244800 \t transport_size:103.8336M\n",
      "------------------------------------------------------------------\n",
      "7-Conv2d computation time: 0.055000 s\n",
      "output shape: torch.Size([100, 384, 13, 13]) \t transport_num:6489600 \t transport_size:207.6672M\n",
      "weight  :  parameters size torch.Size([384, 192, 3, 3]) \t parameters number 663552\n",
      "bias  :  parameters size torch.Size([384]) \t parameters number 384\n",
      "------------------------------------------------------------------\n",
      "8-ReLU computation time: 0.003000 s\n",
      "output shape: torch.Size([100, 384, 13, 13]) \t transport_num:6489600 \t transport_size:207.6672M\n",
      "------------------------------------------------------------------\n",
      "9-Conv2d computation time: 0.071000 s\n",
      "output shape: torch.Size([100, 256, 13, 13]) \t transport_num:4326400 \t transport_size:138.4448M\n",
      "weight  :  parameters size torch.Size([256, 384, 3, 3]) \t parameters number 884736\n",
      "bias  :  parameters size torch.Size([256]) \t parameters number 256\n",
      "------------------------------------------------------------------\n",
      "10-ReLU computation time: 0.001000 s\n",
      "output shape: torch.Size([100, 256, 13, 13]) \t transport_num:4326400 \t transport_size:138.4448M\n",
      "------------------------------------------------------------------\n",
      "11-Conv2d computation time: 0.045000 s\n",
      "output shape: torch.Size([100, 256, 13, 13]) \t transport_num:4326400 \t transport_size:138.4448M\n",
      "weight  :  parameters size torch.Size([256, 256, 3, 3]) \t parameters number 589824\n",
      "bias  :  parameters size torch.Size([256]) \t parameters number 256\n",
      "------------------------------------------------------------------\n",
      "12-ReLU computation time: 0.004000 s\n",
      "output shape: torch.Size([100, 256, 13, 13]) \t transport_num:4326400 \t transport_size:138.4448M\n",
      "------------------------------------------------------------------\n",
      "13-MaxPool2d computation time: 0.005000 s\n",
      "output shape: torch.Size([100, 256, 6, 6]) \t transport_num:921600 \t transport_size:29.4912M\n",
      "------------------------------------------------------------------\n",
      "14-AdaptiveAvgPool2d computation time: 0.011000 s\n",
      "output shape: torch.Size([100, 256, 6, 6]) \t transport_num:921600 \t transport_size:29.4912M\n",
      "------------------------------------------------------------------\n",
      "15-Flatten computation time: 0.000000 s\n",
      "output shape: torch.Size([100, 9216]) \t transport_num:921600 \t transport_size:29.4912M\n",
      "------------------------------------------------------------------\n",
      "16-Dropout computation time: 0.022000 s\n",
      "output shape: torch.Size([100, 9216]) \t transport_num:921600 \t transport_size:29.4912M\n",
      "------------------------------------------------------------------\n",
      "17-Linear computation time: 0.058000 s\n",
      "output shape: torch.Size([100, 4096]) \t transport_num:409600 \t transport_size:13.1072M\n",
      "weight  :  parameters size torch.Size([4096, 9216]) \t parameters number 37748736\n",
      "bias  :  parameters size torch.Size([4096]) \t parameters number 4096\n",
      "------------------------------------------------------------------\n",
      "18-ReLU computation time: 0.000000 s\n",
      "output shape: torch.Size([100, 4096]) \t transport_num:409600 \t transport_size:13.1072M\n",
      "------------------------------------------------------------------\n",
      "19-Dropout computation time: 0.003000 s\n",
      "output shape: torch.Size([100, 4096]) \t transport_num:409600 \t transport_size:13.1072M\n",
      "------------------------------------------------------------------\n",
      "20-Linear computation time: 0.030000 s\n",
      "output shape: torch.Size([100, 4096]) \t transport_num:409600 \t transport_size:13.1072M\n",
      "weight  :  parameters size torch.Size([4096, 4096]) \t parameters number 16777216\n",
      "bias  :  parameters size torch.Size([4096]) \t parameters number 4096\n",
      "------------------------------------------------------------------\n",
      "21-ReLU computation time: 0.003000 s\n",
      "output shape: torch.Size([100, 4096]) \t transport_num:409600 \t transport_size:13.1072M\n",
      "------------------------------------------------------------------\n",
      "22-Linear computation time: 0.006000 s\n",
      "output shape: torch.Size([100, 1000]) \t transport_num:100000 \t transport_size:3.2M\n",
      "weight  :  parameters size torch.Size([1000, 4096]) \t parameters number 4096000\n",
      "bias  :  parameters size torch.Size([1000]) \t parameters number 1000\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    尝试分解每层的计算量和参数量\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "x = torch.rand(size=(100,3,224,224))\n",
    "x = x.to(device)\n",
    "alexNet2 = alexnet(input_layer = 3,num_classes = 1000)\n",
    "print(next(alexNet2.parameters()).device)\n",
    "\n",
    "idx = 1\n",
    "for layer in alexNet2:\n",
    "    start_time = int(round(time.time() * 1000))\n",
    "    x = layer(x)\n",
    "    end_time = int(round(time.time() * 1000))\n",
    "    # print(x.device)\n",
    "\n",
    "    # 计算分割点 中间传输占用大小为多少m  主要与网络传输时延相关\n",
    "    total_num = 1\n",
    "    for num in x.shape:\n",
    "        total_num *= num\n",
    "    type_size = 32\n",
    "    size = total_num * type_size / 1000 /1000\n",
    "\n",
    "    print(\"------------------------------------------------------------------\")\n",
    "    print(f'{idx}-{layer.__class__.__name__} computation time: {(end_time - start_time)/1000 :>3f} s\\n'\n",
    "          f'output shape: {x.shape} \\t transport_num:{total_num} \\t transport_size:{size}M')\n",
    "\n",
    "    # 计算各层的结构所包含的参数量 主要与计算时延相关\n",
    "    # para = parameters.numel()\n",
    "    for name,parameters in layer.named_parameters():\n",
    "        print(f\"{name}  :  parameters size {parameters.size()} \\t parameters number {parameters.numel()}\")\n",
    "    idx += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}