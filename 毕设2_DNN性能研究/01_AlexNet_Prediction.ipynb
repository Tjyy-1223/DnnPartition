{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "\n",
    "# 获取alexNet预训练参数\n",
    "# alexNet = models.alexnet(pretrained=True)\n",
    "# torch.save(alexNet.state_dict(),'alexNet_weights.pth')\n",
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "from a0_alexNet import show_features\n",
    "from a0_alexNet import AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    使用与训练好的参数先预测一波fashionmnis图像分类的准确率\n",
    "\"\"\"\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "resize = 224\n",
    "trans = transforms.Compose([\n",
    "    transforms.Resize(resize),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "training_data = datasets.FashionMNIST(root = \"../data\",train=True,download=False,transform=trans)\n",
    "test_data = datasets.FashionMNIST(root = \"../data\",train=False,download=True,transform=trans)\n",
    "\n",
    "mytest_data = []\n",
    "for idx,(x,y) in enumerate(test_data):\n",
    "    mytest_data.append((torch.cat((x,x,x),dim=0),y))\n",
    "\n",
    "train_dataloader = DataLoader(training_data,batch_size=64,shuffle=True)\n",
    "test_dataloader = DataLoader(mytest_data,batch_size=64,shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all number: 640   correct number: 71.0\n",
      "Accuracy:  11.1% , avg loss :2.302317\n",
      "--------------------------------------------------\n",
      "all number: 1280   correct number: 135.0\n",
      "Accuracy:  10.5% , avg loss :2.302852\n",
      "--------------------------------------------------\n",
      "all number: 1920   correct number: 190.0\n",
      "Accuracy:  9.9% , avg loss :2.303447\n",
      "--------------------------------------------------\n",
      "all number: 2560   correct number: 254.0\n",
      "Accuracy:  9.9% , avg loss :2.303333\n",
      "--------------------------------------------------\n",
      "all number: 3200   correct number: 315.0\n",
      "Accuracy:  9.8% , avg loss :2.303320\n",
      "--------------------------------------------------\n",
      "all number: 3840   correct number: 370.0\n",
      "Accuracy:  9.6% , avg loss :2.303298\n",
      "--------------------------------------------------\n",
      "all number: 4480   correct number: 424.0\n",
      "Accuracy:  9.5% , avg loss :2.303272\n",
      "--------------------------------------------------\n",
      "all number: 5120   correct number: 478.0\n",
      "Accuracy:  9.3% , avg loss :2.303099\n",
      "--------------------------------------------------\n",
      "all number: 5760   correct number: 549.0\n",
      "Accuracy:  9.5% , avg loss :2.302919\n",
      "--------------------------------------------------\n",
      "all number: 6400   correct number: 624.0\n",
      "Accuracy:  9.8% , avg loss :2.302738\n",
      "--------------------------------------------------\n",
      "all number: 7040   correct number: 701.0\n",
      "Accuracy:  10.0% , avg loss :2.302736\n",
      "--------------------------------------------------\n",
      "all number: 7680   correct number: 763.0\n",
      "Accuracy:  9.9% , avg loss :2.302824\n",
      "--------------------------------------------------\n",
      "all number: 8320   correct number: 837.0\n",
      "Accuracy:  10.1% , avg loss :2.302854\n",
      "--------------------------------------------------\n",
      "all number: 8960   correct number: 902.0\n",
      "Accuracy:  10.1% , avg loss :2.302873\n",
      "--------------------------------------------------\n",
      "all number: 9600   correct number: 964.0\n",
      "Accuracy:  10.0% , avg loss :2.302840\n",
      "--------------------------------------------------\n",
      "test error :\n",
      " Accuracy:  10.0 , avg loss :2.302849\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    测定test数据集准确率\n",
    "    batch input [64,1,224,224]\n",
    "    batch label [64]\n",
    "\n",
    "    batch output [64,10]\n",
    "\"\"\"\n",
    "def test(dataloader,model,loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss,correct,all = 0,0,0\n",
    "    with torch.no_grad():\n",
    "        for idx,(X,y) in enumerate(dataloader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            all += 64\n",
    "            # X,y = X.to(device),y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred,y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "            if(all % 640 == 0):\n",
    "                print(f\"all number: {all}   correct number: {correct}\")\n",
    "                print(f\"Accuracy: {(100*(correct/all)) :> 0.1f}% , avg loss :{test_loss/(idx+1):>8f}\")\n",
    "                print(f\"--------------------------------------------------\")\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"test error :\\n Accuracy: {(100*correct) :> 0.1f} , avg loss :{test_loss:>8f}\")\n",
    "\n",
    "# 预训练最后输出维度1000 所以目前fashion数据集只能多加个 linear 1000->10\n",
    "# 后续换成cifar-10 数据集可以正常运行\n",
    "alexNet = nn.Sequential(\n",
    "    AlexNet(input_layer=3,num_classes=1000),\n",
    "    nn.Linear(1000,10),\n",
    ").to(device)\n",
    "test(test_dataloader,alexNet,nn.CrossEntropyLoss())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "1 - Conv2d -output shape:\t torch.Size([10000, 64, 55, 55]) \t computation time: 29.499 s\n",
      "2 - ReLU -output shape:\t torch.Size([10000, 64, 55, 55]) \t computation time: 2.025 s\n",
      "3 - MaxPool2d -output shape:\t torch.Size([10000, 64, 27, 27]) \t computation time: 3.680 s\n",
      "4 - Conv2d -output shape:\t torch.Size([10000, 192, 27, 27]) \t computation time: 40.644 s\n",
      "5 - ReLU -output shape:\t torch.Size([10000, 192, 27, 27]) \t computation time: 0.189 s\n",
      "6 - MaxPool2d -output shape:\t torch.Size([10000, 192, 13, 13]) \t computation time: 2.673 s\n",
      "7 - Conv2d -output shape:\t torch.Size([10000, 384, 13, 13]) \t computation time: 10.213 s\n",
      "8 - ReLU -output shape:\t torch.Size([10000, 384, 13, 13]) \t computation time: 0.418 s\n",
      "9 - Conv2d -output shape:\t torch.Size([10000, 256, 13, 13]) \t computation time: 11.195 s\n",
      "10 - ReLU -output shape:\t torch.Size([10000, 256, 13, 13]) \t computation time: 0.166 s\n",
      "11 - Conv2d -output shape:\t torch.Size([10000, 256, 13, 13]) \t computation time: 6.970 s\n",
      "12 - ReLU -output shape:\t torch.Size([10000, 256, 13, 13]) \t computation time: 0.307 s\n",
      "13 - MaxPool2d -output shape:\t torch.Size([10000, 256, 6, 6]) \t computation time: 0.712 s\n",
      "14 - AdaptiveAvgPool2d -output shape:\t torch.Size([10000, 256, 6, 6]) \t computation time: 0.160 s\n",
      "15 - Flatten -output shape:\t torch.Size([10000, 9216]) \t computation time: 0.004 s\n",
      "16 - Dropout -output shape:\t torch.Size([10000, 9216]) \t computation time: 0.641 s\n",
      "17 - Linear -output shape:\t torch.Size([10000, 4096]) \t computation time: 2.243 s\n",
      "18 - ReLU -output shape:\t torch.Size([10000, 4096]) \t computation time: 0.005 s\n",
      "19 - Dropout -output shape:\t torch.Size([10000, 4096]) \t computation time: 0.245 s\n",
      "20 - Linear -output shape:\t torch.Size([10000, 4096]) \t computation time: 1.001 s\n",
      "21 - ReLU -output shape:\t torch.Size([10000, 4096]) \t computation time: 0.006 s\n",
      "22 - Linear -output shape:\t torch.Size([10000, 1000]) \t computation time: 0.319 s\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    尝试分解每层的计算\n",
    "\"\"\"\n",
    "import time\n",
    "x = torch.rand(size=(10000,3,224,224))\n",
    "x = x.to(device)\n",
    "alexNet2 = AlexNet(input_layer = 3,num_classes = 1000)\n",
    "print(next(alexNet2.parameters()).device)\n",
    "\n",
    "id = 1\n",
    "for layer in alexNet2:\n",
    "    start_time = int(round(time.time() * 1000))\n",
    "    x = layer(x)\n",
    "    end_time = int(round(time.time() * 1000))\n",
    "    # print(x.device)\n",
    "    print(id,\"-\",layer.__class__.__name__,f'-output shape:\\t',x.shape,\n",
    "          f'\\t computation time: {(end_time - start_time)/1000 :>.3f} s')\n",
    "    id += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    ")\n",
    "\n",
    "print(len(model))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "------------------------------------------------------------------\n",
      "1-Conv2d computation time: 30.019000 s\n",
      "output shape: torch.Size([10000, 64, 55, 55]) \t transport_num:1936000000 \t transport_size:61952.0M\n",
      "weight  :  parameters size torch.Size([64, 3, 11, 11]) \t parameters number 23232\n",
      "bias  :  parameters size torch.Size([64]) \t parameters number 64\n",
      "------------------------------------------------------------------\n",
      "2-ReLU computation time: 2.145000 s\n",
      "output shape: torch.Size([10000, 64, 55, 55]) \t transport_num:1936000000 \t transport_size:61952.0M\n",
      "------------------------------------------------------------------\n",
      "3-MaxPool2d computation time: 3.739000 s\n",
      "output shape: torch.Size([10000, 64, 27, 27]) \t transport_num:466560000 \t transport_size:14929.92M\n",
      "------------------------------------------------------------------\n",
      "4-Conv2d computation time: 29.489000 s\n",
      "output shape: torch.Size([10000, 192, 27, 27]) \t transport_num:1399680000 \t transport_size:44789.76M\n",
      "weight  :  parameters size torch.Size([192, 64, 5, 5]) \t parameters number 307200\n",
      "bias  :  parameters size torch.Size([192]) \t parameters number 192\n",
      "------------------------------------------------------------------\n",
      "5-ReLU computation time: 0.201000 s\n",
      "output shape: torch.Size([10000, 192, 27, 27]) \t transport_num:1399680000 \t transport_size:44789.76M\n",
      "------------------------------------------------------------------\n",
      "6-MaxPool2d computation time: 2.899000 s\n",
      "output shape: torch.Size([10000, 192, 13, 13]) \t transport_num:324480000 \t transport_size:10383.36M\n",
      "------------------------------------------------------------------\n",
      "7-Conv2d computation time: 10.008000 s\n",
      "output shape: torch.Size([10000, 384, 13, 13]) \t transport_num:648960000 \t transport_size:20766.72M\n",
      "weight  :  parameters size torch.Size([384, 192, 3, 3]) \t parameters number 663552\n",
      "bias  :  parameters size torch.Size([384]) \t parameters number 384\n",
      "------------------------------------------------------------------\n",
      "8-ReLU computation time: 0.302000 s\n",
      "output shape: torch.Size([10000, 384, 13, 13]) \t transport_num:648960000 \t transport_size:20766.72M\n",
      "------------------------------------------------------------------\n",
      "9-Conv2d computation time: 11.083000 s\n",
      "output shape: torch.Size([10000, 256, 13, 13]) \t transport_num:432640000 \t transport_size:13844.48M\n",
      "weight  :  parameters size torch.Size([256, 384, 3, 3]) \t parameters number 884736\n",
      "bias  :  parameters size torch.Size([256]) \t parameters number 256\n",
      "------------------------------------------------------------------\n",
      "10-ReLU computation time: 0.123000 s\n",
      "output shape: torch.Size([10000, 256, 13, 13]) \t transport_num:432640000 \t transport_size:13844.48M\n",
      "------------------------------------------------------------------\n",
      "11-Conv2d computation time: 6.959000 s\n",
      "output shape: torch.Size([10000, 256, 13, 13]) \t transport_num:432640000 \t transport_size:13844.48M\n",
      "weight  :  parameters size torch.Size([256, 256, 3, 3]) \t parameters number 589824\n",
      "bias  :  parameters size torch.Size([256]) \t parameters number 256\n",
      "------------------------------------------------------------------\n",
      "12-ReLU computation time: 0.174000 s\n",
      "output shape: torch.Size([10000, 256, 13, 13]) \t transport_num:432640000 \t transport_size:13844.48M\n",
      "------------------------------------------------------------------\n",
      "13-MaxPool2d computation time: 0.675000 s\n",
      "output shape: torch.Size([10000, 256, 6, 6]) \t transport_num:92160000 \t transport_size:2949.12M\n",
      "------------------------------------------------------------------\n",
      "14-AdaptiveAvgPool2d computation time: 0.142000 s\n",
      "output shape: torch.Size([10000, 256, 6, 6]) \t transport_num:92160000 \t transport_size:2949.12M\n",
      "------------------------------------------------------------------\n",
      "15-Flatten computation time: 0.013000 s\n",
      "output shape: torch.Size([10000, 9216]) \t transport_num:92160000 \t transport_size:2949.12M\n",
      "------------------------------------------------------------------\n",
      "16-Dropout computation time: 0.561000 s\n",
      "output shape: torch.Size([10000, 9216]) \t transport_num:92160000 \t transport_size:2949.12M\n",
      "------------------------------------------------------------------\n",
      "17-Linear computation time: 2.427000 s\n",
      "output shape: torch.Size([10000, 4096]) \t transport_num:40960000 \t transport_size:1310.72M\n",
      "weight  :  parameters size torch.Size([4096, 9216]) \t parameters number 37748736\n",
      "bias  :  parameters size torch.Size([4096]) \t parameters number 4096\n",
      "------------------------------------------------------------------\n",
      "18-ReLU computation time: 0.006000 s\n",
      "output shape: torch.Size([10000, 4096]) \t transport_num:40960000 \t transport_size:1310.72M\n",
      "------------------------------------------------------------------\n",
      "19-Dropout computation time: 0.241000 s\n",
      "output shape: torch.Size([10000, 4096]) \t transport_num:40960000 \t transport_size:1310.72M\n",
      "------------------------------------------------------------------\n",
      "20-Linear computation time: 1.068000 s\n",
      "output shape: torch.Size([10000, 4096]) \t transport_num:40960000 \t transport_size:1310.72M\n",
      "weight  :  parameters size torch.Size([4096, 4096]) \t parameters number 16777216\n",
      "bias  :  parameters size torch.Size([4096]) \t parameters number 4096\n",
      "------------------------------------------------------------------\n",
      "21-ReLU computation time: 0.006000 s\n",
      "output shape: torch.Size([10000, 4096]) \t transport_num:40960000 \t transport_size:1310.72M\n",
      "------------------------------------------------------------------\n",
      "22-Linear computation time: 0.328000 s\n",
      "output shape: torch.Size([10000, 1000]) \t transport_num:10000000 \t transport_size:320.0M\n",
      "weight  :  parameters size torch.Size([1000, 4096]) \t parameters number 4096000\n",
      "bias  :  parameters size torch.Size([1000]) \t parameters number 1000\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    尝试分解每层的计算量和参数量\n",
    "\"\"\"\n",
    "x = torch.rand(size=(10000,3,224,224))\n",
    "x = x.to(device)\n",
    "alexNet2 = AlexNet(input_layer = 3,num_classes = 1000)\n",
    "print(next(alexNet2.parameters()).device)\n",
    "\n",
    "x = show_features(alexNet2,x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}